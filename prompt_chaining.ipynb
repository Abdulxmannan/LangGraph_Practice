{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67f3f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a25d4602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6b26b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f3a6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogState(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str\n",
    "    feedback: str\n",
    "    grades: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef31dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: BlogState) -> BlogState:\n",
    "\n",
    "    # fetch title\n",
    "    title = state['title']\n",
    "\n",
    "    # call llm gen outline\n",
    "    prompt = f'Generate a detailed outline for a blog on the topic - {title}'\n",
    "    outline = model.invoke(prompt).content\n",
    "\n",
    "    # update state\n",
    "    state['outline'] = outline\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81a6d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_blog(state: BlogState) -> BlogState:\n",
    "    title = state[\"title\"]\n",
    "    outline = state[\"outline\"]\n",
    "    prompt = f\"Write a blog post based on the title '{title}' and the following outline:\\n{outline}\"\n",
    "    content = model.invoke(prompt).content\n",
    "    state[\"content\"] = content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5940d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_blog(state: BlogState) -> BlogState:\n",
    "    content = state[\"content\"]\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate the following blog post for the following criteria:\n",
    "    - Clarity\n",
    "    - Engagement\n",
    "    - Informativeness\n",
    "\n",
    "    For each criterion, give a numeric score from 1 to 10.\n",
    "    Then provide an overall written feedback.\n",
    "\n",
    "    Blog content:\n",
    "    {content}\n",
    "\n",
    "    Return your response strictly in this JSON format:\n",
    "    {{\n",
    "        \"grades\": {{\n",
    "            \"clarity\": <1-10>,\n",
    "            \"engagement\": <1-10>,\n",
    "            \"informativeness\": <1-10>\n",
    "        }},\n",
    "        \"feedback\": \"<Your detailed written feedback here>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.invoke(prompt).content.strip()\n",
    "\n",
    "    # Try parsing structured JSON response\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "        state[\"grades\"] = data.get(\"grades\", {})\n",
    "        state[\"feedback\"] = data.get(\"feedback\", \"\")\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback if the LLM gives non-JSON output\n",
    "        state[\"grades\"] = {}\n",
    "        state[\"feedback\"] = response\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3517424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(BlogState)\n",
    "\n",
    "graph.add_node(\"Create_outline\", create_outline)\n",
    "graph.add_node(\"Create_blog\", Create_blog)\n",
    "graph.add_node(\"Evaluate_blog\", evaluate_blog)\n",
    "\n",
    "graph.add_edge(START, \"Create_outline\")\n",
    "graph.add_edge(\"Create_outline\", \"Create_blog\")\n",
    "graph.add_edge(\"Create_blog\", \"Evaluate_blog\")\n",
    "graph.add_edge(\"Evaluate_blog\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28122183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∞ Blog Title: The Future of AI in Everyday Life\n",
      "\n",
      "üìä Grades: {}\n",
      "\n",
      "üí¨ Editor Feedback:\n",
      " {\n",
      "  \"grades\": {\n",
      "    \"clarity\": 9,\n",
      "    \"engagement\": 8,\n",
      "    \"informativeness\": 9\n",
      "  },\n",
      "  \"feedback\": \"The blog post presents a comprehensive overview of the future of AI in everyday life, covering various aspects such as home automation, healthcare, transportation, education, job market, social interactions, and ethical considerations. The writing is clear and concise, making it easy to follow and understand the concepts. The structure is well-organized, with each section providing a clear and concise overview of the topic.\n",
      "\n",
      "The engagement score is lower due to the lack of personal anecdotes, examples, or real-life scenarios that might make the content more relatable and interesting to the readers. However, the use of technical terms and concepts is well-explained, making it accessible to a general audience.\n",
      "\n",
      "The informativeness score is high due to the thorough coverage of the topic. The author provides a detailed overview of the current state and future developments in various fields, including the benefits and challenges associated with AI adoption. The inclusion of references at the end of the post adds credibility to the content and provides readers with a starting point for further research.\n",
      "\n",
      "Overall, the blog post is well-structured, clear, and informative, making it a valuable resource for readers looking to understand the future of AI in everyday life. However, incorporating more engaging and interactive elements could enhance the reader's experience and make the content more memorable.\"\n",
      "}\n",
      "\n",
      "üìù Blog Preview:\n",
      " **The Future of AI in Everyday Life: Revolutionizing Our World**\n",
      "\n",
      "As we continue to navigate the complexities of the 21st century, artificial intelligence (AI) has emerged as a transformative force that is revolutionizing various aspects of our daily lives. From home automation and healthcare to education and employment, AI is transforming the way we live, work, and interact with each other. In this blog post, we will explore the future of AI in everyday life, discussing its current applications, future developments, and the potential benefits and challenges associated with its adoption.\n",
      "\n",
      "**I. Introduction**\n",
      "\n",
      "Artificial intelligence has come a long way since its inception in the 1950s. Today ...\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\"title\": \"The Future of AI in Everyday Life\"}\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\nüì∞ Blog Title:\", final_state[\"title\"])\n",
    "print(\"\\nüìä Grades:\", final_state[\"grades\"])\n",
    "print(\"\\nüí¨ Editor Feedback:\\n\", final_state[\"feedback\"])\n",
    "print(\"\\nüìù Blog Preview:\\n\", final_state[\"content\"][:700], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fd400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
