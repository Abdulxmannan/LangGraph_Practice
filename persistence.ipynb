{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f7a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "953b2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8281c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    joke : str\n",
    "    topic : str\n",
    "    explaination:str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84688708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke(state: JokeState):\n",
    "    prompt = f'generate a joke on {state[\"topic\"]}'\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return{\"joke\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e06f1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JokeExplaination(state: JokeState):\n",
    "    prompt = f'generate an explaination on {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return{\"explaination\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7528a9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001FB06EAB4A0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('joke', joke)\n",
    "graph.add_node('JokeExplaination', JokeExplaination)\n",
    "\n",
    "graph.add_edge(START,'joke')\n",
    "graph.add_edge('joke','JokeExplaination')\n",
    "graph.add_edge('JokeExplaination', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "551a1463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}),\n",
       " 'topic': 'pizza',\n",
       " 'explaination': AIMessage(content='**Explanation of Content: A Pizza-Related Pun**\\n\\nThe provided content is a simple joke in the format of a question and answer. Here\\'s a breakdown of the content:\\n\\n* `Why did the pizza go to the doctor?`: This is the question part of the joke, setting up the unexpected punchline.\\n* `\\\\n\\\\nBecause it was feeling a little crusty.`: This is the answer part of the joke, where the pun is revealed. The word \"crusty\" has a double meaning here - it can refer to the crust of a pizza, but it can also imply that someone or something is a bit \"off\" or feeling unwell, which is why the pizza went to the doctor.\\n\\n**Additional Context and Metadata**\\n\\nThe additional_kwargs dictionary is empty, which means there are no additional parameters or context provided for this content.\\n\\nThe response_metadata dictionary provides information about the generation of this content:\\n\\n* `token_usage`: This section provides details about the token usage during the generation of this content, including the number of completion tokens, prompt tokens, total tokens, completion time, prompt time, queue time, and total time. The completion time is approximately 26 milliseconds, and the prompt time is approximately 2 milliseconds.\\n* `model_name`: The name of the model used to generate this content is `llama-3.1-8b-instant`.\\n* `system_fingerprint`: A unique identifier for the system that generated this content is `fp_7b3cfae3af`.\\n* `service_tier`: The service tier used to generate this content is `on_demand`.\\n* `finish_reason`: The reason why the content generation was stopped is `stop`.\\n* `logprobs`: This field is empty, indicating that no log probabilities were provided for this content.\\n* `model_provider`: The provider of the model used to generate this content is `groq`.\\n\\nThe id field is a unique identifier for this content generation run, and the usage_metadata dictionary provides information about the input and output tokens used during the generation of this content.\\n\\n**Usage Metadata**\\n\\nThe usage_metadata dictionary provides information about the usage of this content:\\n\\n* `input_tokens`: The number of input tokens used during the generation of this content is 40.\\n* `output_tokens`: The number of output tokens generated during the generation of this content is 20.\\n* `total_tokens`: The total number of tokens used during the generation of this content is 60.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 254, 'total_tokens': 754, 'completion_time': 0.831993883, 'prompt_time': 0.013884733, 'queue_time': 0.050841216, 'total_time': 0.845878616}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--be695141-5f79-4556-abff-1be29e4e6e2a-0', usage_metadata={'input_tokens': 254, 'output_tokens': 500, 'total_tokens': 754})}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1= {\"configurable\":{'thread_id':'1'}}\n",
    "workflow.invoke({'topic':'pizza'}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b0346cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'pizza', 'explaination': AIMessage(content='**Explanation of Content: A Pizza-Related Pun**\\n\\nThe provided content is a simple joke in the format of a question and answer. Here\\'s a breakdown of the content:\\n\\n* `Why did the pizza go to the doctor?`: This is the question part of the joke, setting up the unexpected punchline.\\n* `\\\\n\\\\nBecause it was feeling a little crusty.`: This is the answer part of the joke, where the pun is revealed. The word \"crusty\" has a double meaning here - it can refer to the crust of a pizza, but it can also imply that someone or something is a bit \"off\" or feeling unwell, which is why the pizza went to the doctor.\\n\\n**Additional Context and Metadata**\\n\\nThe additional_kwargs dictionary is empty, which means there are no additional parameters or context provided for this content.\\n\\nThe response_metadata dictionary provides information about the generation of this content:\\n\\n* `token_usage`: This section provides details about the token usage during the generation of this content, including the number of completion tokens, prompt tokens, total tokens, completion time, prompt time, queue time, and total time. The completion time is approximately 26 milliseconds, and the prompt time is approximately 2 milliseconds.\\n* `model_name`: The name of the model used to generate this content is `llama-3.1-8b-instant`.\\n* `system_fingerprint`: A unique identifier for the system that generated this content is `fp_7b3cfae3af`.\\n* `service_tier`: The service tier used to generate this content is `on_demand`.\\n* `finish_reason`: The reason why the content generation was stopped is `stop`.\\n* `logprobs`: This field is empty, indicating that no log probabilities were provided for this content.\\n* `model_provider`: The provider of the model used to generate this content is `groq`.\\n\\nThe id field is a unique identifier for this content generation run, and the usage_metadata dictionary provides information about the input and output tokens used during the generation of this content.\\n\\n**Usage Metadata**\\n\\nThe usage_metadata dictionary provides information about the usage of this content:\\n\\n* `input_tokens`: The number of input tokens used during the generation of this content is 40.\\n* `output_tokens`: The number of output tokens generated during the generation of this content is 20.\\n* `total_tokens`: The total number of tokens used during the generation of this content is 60.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 254, 'total_tokens': 754, 'completion_time': 0.831993883, 'prompt_time': 0.013884733, 'queue_time': 0.050841216, 'total_time': 0.845878616}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--be695141-5f79-4556-abff-1be29e4e6e2a-0', usage_metadata={'input_tokens': 254, 'output_tokens': 500, 'total_tokens': 754})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-8df9-6c57-8002-845193cfbb83'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-05T10:23:56.100514+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-82ee-68cb-8001-a8b46d9bfe7b'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af428a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 40, 'total_tokens': 71, 'completion_time': 0.031463177, 'prompt_time': 0.001771714, 'queue_time': 0.053036772, 'total_time': 0.033234891}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--45e4d1c0-dc60-45b8-8ece-e8ddc61d6e5c-0', usage_metadata={'input_tokens': 40, 'output_tokens': 31, 'total_tokens': 71}),\n",
       " 'topic': 'pasta',\n",
       " 'explaination': AIMessage(content='**Explanation of Content: A Play on Words**\\n\\nThe content provided is a play on words that uses a common phrase \"feeling a little twisted\" and gives it a literal and humorous spin by applying it to a piece of spaghetti, which is a type of twisted pasta.\\n\\n**Breaking Down the Joke:**\\n\\n1. **\"Why did the spaghetti go to therapy?\"**: This is a common setup for a joke that implies the spaghetti has a problem.\\n2. **\"Because it was feeling a little \\'twisted\\'\":** This is the punchline, where the word \"twisted\" has a double meaning. Spaghetti is literally twisted into its shape, but the phrase \"feeling a little twisted\" is also an idiomatic expression meaning feeling anxious or upset.\\n3. **\"and had a lot of \\'noodle\\' issues\":** This is a further play on words, where the word \"noodle\" has a double meaning. A noodle is a type of pasta, but it\\'s also a colloquialism for problems or issues.\\n\\n**The Humor:**\\n\\nThe humor in this joke comes from the unexpected twist (pun intended) on the phrase \"feeling a little twisted\" and the clever use of wordplay with \"noodle\" issues. It\\'s a lighthearted and silly joke that uses a common phrase and gives it a silly and unexpected spin.\\n\\n**Metadata:**\\n\\nThe provided metadata gives information about the response generated by a language model, including:\\n\\n* **Token usage:** The number of tokens (words or characters) used in the prompt and completion.\\n* **Model information:** The name and version of the language model used, as well as the provider and service tier.\\n* **Request metadata:** The ID of the request and the reason why the model stopped generating text.\\n\\nHowever, as this is an AI generated response, it is not possible to verify or validate the authenticity of the metadata.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 268, 'total_tokens': 663, 'completion_time': 0.673231349, 'prompt_time': 0.016629032, 'queue_time': 0.050599767, 'total_time': 0.689860381}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b60c8944-3b83-4238-b315-7fc43c88dae7-0', usage_metadata={'input_tokens': 268, 'output_tokens': 395, 'total_tokens': 663})}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={'configurable':{'thread_id':'2'}}\n",
    "workflow.invoke({'topic':'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba34827e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and had a lot of \"noodle\" issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 40, 'total_tokens': 71, 'completion_time': 0.031463177, 'prompt_time': 0.001771714, 'queue_time': 0.053036772, 'total_time': 0.033234891}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--45e4d1c0-dc60-45b8-8ece-e8ddc61d6e5c-0', usage_metadata={'input_tokens': 40, 'output_tokens': 31, 'total_tokens': 71}), 'topic': 'pasta', 'explaination': AIMessage(content='**Explanation of Content: A Play on Words**\\n\\nThe content provided is a play on words that uses a common phrase \"feeling a little twisted\" and gives it a literal and humorous spin by applying it to a piece of spaghetti, which is a type of twisted pasta.\\n\\n**Breaking Down the Joke:**\\n\\n1. **\"Why did the spaghetti go to therapy?\"**: This is a common setup for a joke that implies the spaghetti has a problem.\\n2. **\"Because it was feeling a little \\'twisted\\'\":** This is the punchline, where the word \"twisted\" has a double meaning. Spaghetti is literally twisted into its shape, but the phrase \"feeling a little twisted\" is also an idiomatic expression meaning feeling anxious or upset.\\n3. **\"and had a lot of \\'noodle\\' issues\":** This is a further play on words, where the word \"noodle\" has a double meaning. A noodle is a type of pasta, but it\\'s also a colloquialism for problems or issues.\\n\\n**The Humor:**\\n\\nThe humor in this joke comes from the unexpected twist (pun intended) on the phrase \"feeling a little twisted\" and the clever use of wordplay with \"noodle\" issues. It\\'s a lighthearted and silly joke that uses a common phrase and gives it a silly and unexpected spin.\\n\\n**Metadata:**\\n\\nThe provided metadata gives information about the response generated by a language model, including:\\n\\n* **Token usage:** The number of tokens (words or characters) used in the prompt and completion.\\n* **Model information:** The name and version of the language model used, as well as the provider and service tier.\\n* **Request metadata:** The ID of the request and the reason why the model stopped generating text.\\n\\nHowever, as this is an AI generated response, it is not possible to verify or validate the authenticity of the metadata.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 268, 'total_tokens': 663, 'completion_time': 0.673231349, 'prompt_time': 0.016629032, 'queue_time': 0.050599767, 'total_time': 0.689860381}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b60c8944-3b83-4238-b315-7fc43c88dae7-0', usage_metadata={'input_tokens': 268, 'output_tokens': 395, 'total_tokens': 663})}, next=(), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba31c-a5d9-60eb-8006-8a10c2ec4aa8'}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, created_at='2025-11-05T10:25:45.977879+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba31c-9ced-644a-8005-6f2c0415a436'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config=config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7184b",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06862735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'samosa'}, next=('JokeExplaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba359-2d88-67a0-8001-adf795b5c575'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2025-11-05T10:52:50.818243+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}}, tasks=(PregelTask(id='b8052038-1378-611f-464b-d4d61fb406ba', name='JokeExplaination', path=('__pregel_pull', 'JokeExplaination'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'samosa', 'explaination': AIMessage(content='**Content Explanation: \"Why did the pizza go to the doctor? \\\\n\\\\nBecause it was feeling a little crusty.\"**\\n\\nThe given content appears to be a lighthearted and humorous example of a joke. The structure of the joke is as follows:\\n\\n1. **Setup**: \"Why did the pizza go to the doctor?\" - This is the question that sets the scene for the punchline.\\n2. **Punchline**: \"Because it was feeling a little crusty.\" - This is the humorous answer that resolves the setup. The word \"crusty\" has a double meaning here, referring both to the crust of a pizza and the fact that the pizza is feeling unwell, hence \"crusty\" in a colloquial sense.\\n\\n**Key Features of the Joke:**\\n\\n- **Wordplay**: The joke relies on wordplay, using the multiple meanings of the word \"crusty\" to create a pun.\\n- **Simple setup**: The setup is straightforward and easy to understand, making it accessible to a wide audience.\\n- **Short and punchy punchline**: The punchline is short, snappy, and to the point, delivering the humor in a concise manner.\\n\\n**Use Cases:**\\n\\n- **Comedic writing**: This joke can be used in comedic writing, such as in scripts for stand-up comedy, sitcoms, or comedy sketches.\\n- **Social media content**: The joke can be used as a social media post, tweet, or meme to entertain followers.\\n- **Education**: The joke can be used in educational settings to teach children about wordplay, puns, and the importance of understanding language nuances.\\n\\n**Technical Details:**\\n\\nThe provided response metadata includes information about the model used to generate the content, such as the model name, system fingerprint, and service tier. The metadata also includes details about the computational resources used, such as the number of tokens processed and the time taken to generate the response.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 397, 'prompt_tokens': 254, 'total_tokens': 651, 'completion_time': 0.567313116, 'prompt_time': 0.014030564, 'queue_time': 0.047854136, 'total_time': 0.58134368}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5e74c437-f4dd-4597-9279-e7255218a5d0-0', usage_metadata={'input_tokens': 254, 'output_tokens': 397, 'total_tokens': 651})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba353-9ec2-6e8c-8002-b81406bf9a61'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-05T10:50:21.629812+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba352-83ab-6556-8001-c271b04a6f44'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'samosa'}, next=('JokeExplaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba352-83ab-6556-8001-c271b04a6f44'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2025-11-05T10:49:51.945455+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}}, tasks=(PregelTask(id='30af23c9-5abf-3366-522e-9f7e082d09d5', name='JokeExplaination', path=('__pregel_pull', 'JokeExplaination'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Content Explanation: \"Why did the pizza go to the doctor? \\\\n\\\\nBecause it was feeling a little crusty.\"**\\n\\nThe given content appears to be a lighthearted and humorous example of a joke. The structure of the joke is as follows:\\n\\n1. **Setup**: \"Why did the pizza go to the doctor?\" - This is the question that sets the scene for the punchline.\\n2. **Punchline**: \"Because it was feeling a little crusty.\" - This is the humorous answer that resolves the setup. The word \"crusty\" has a double meaning here, referring both to the crust of a pizza and the fact that the pizza is feeling unwell, hence \"crusty\" in a colloquial sense.\\n\\n**Key Features of the Joke:**\\n\\n- **Wordplay**: The joke relies on wordplay, using the multiple meanings of the word \"crusty\" to create a pun.\\n- **Simple setup**: The setup is straightforward and easy to understand, making it accessible to a wide audience.\\n- **Short and punchy punchline**: The punchline is short, snappy, and to the point, delivering the humor in a concise manner.\\n\\n**Use Cases:**\\n\\n- **Comedic writing**: This joke can be used in comedic writing, such as in scripts for stand-up comedy, sitcoms, or comedy sketches.\\n- **Social media content**: The joke can be used as a social media post, tweet, or meme to entertain followers.\\n- **Education**: The joke can be used in educational settings to teach children about wordplay, puns, and the importance of understanding language nuances.\\n\\n**Technical Details:**\\n\\nThe provided response metadata includes information about the model used to generate the content, such as the model name, system fingerprint, and service tier. The metadata also includes details about the computational resources used, such as the number of tokens processed and the time taken to generate the response.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 397, 'prompt_tokens': 254, 'total_tokens': 651, 'completion_time': 0.567313116, 'prompt_time': 0.014030564, 'queue_time': 0.047854136, 'total_time': 0.58134368}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5e74c437-f4dd-4597-9279-e7255218a5d0-0', usage_metadata={'input_tokens': 254, 'output_tokens': 397, 'total_tokens': 651})}),), interrupts=()),\n",
       " StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'pizza', 'explaination': AIMessage(content='**Content Analysis: A Playful Pizza Joke**\\n\\nThe provided content is a play on words, presenting a pizza-themed joke. The joke is structured as a question and answer, where the question \"Why did the pizza go to the doctor?\" is followed by the punchline \"Because it was feeling a little crusty.\"\\n\\n**Understanding the Joke:**\\n\\nThe joke relies on a clever use of language, where the word \"crusty\" has a double meaning. In culinary terms, a crusty pizza is one with a crunchy, hardened crust. However, in human experience, being \"feeling a little crusty\" can also imply being irritable or feeling under the weather, similar to having a cold or flu.\\n\\n**Key Language Features:**\\n\\n1. **Wordplay:** The joke exploits the dual meaning of the word \"crusty,\" creating a pun that connects the pizza\\'s culinary characteristic with a human emotional state.\\n2. **Misdirection:** The initial question sets up a expectation that the answer will be a serious medical reason for the pizza\\'s visit to the doctor, only to subvert it with a lighthearted and playful punchline.\\n3. **Simplistic yet effective:** The joke\\'s simplicity makes it accessible and easy to understand, while the unexpected twist creates a sense of surprise and delight.\\n\\n**Contextual Considerations:**\\n\\n1. **Audience:** The joke is likely intended for a general audience, particularly those who appreciate wordplay and puns.\\n2. **Tone:** The joke\\'s tone is lighthearted and playful, making it suitable for casual conversations or social media platforms.\\n3. **Cultural relevance:** The joke may not be universally relatable or funny, as pizza and its associated cultural context may vary across different regions and communities.\\n\\n**Conclusion:**\\n\\nThe provided content is a well-crafted play on words that leverages the dual meaning of the word \"crusty\" to create a humorous and engaging joke. Its simplicity, clever use of language, and lighthearted tone make it an effective and entertaining example of a pizza-themed joke.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 429, 'prompt_tokens': 254, 'total_tokens': 683, 'completion_time': 0.811722195, 'prompt_time': 0.013900066, 'queue_time': 0.049151724, 'total_time': 0.825622261}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfa2a6b5-e6e9-49ef-aeea-d422d2621faa-0', usage_metadata={'input_tokens': 254, 'output_tokens': 429, 'total_tokens': 683})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba33c-eae2-6ccb-8002-88535cecb657'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-05T10:40:12.210503+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-82ee-68cb-8001-a8b46d9bfe7b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'pizza', 'explaination': AIMessage(content='**Explanation of Content: A Pizza-Related Pun**\\n\\nThe provided content is a simple joke in the format of a question and answer. Here\\'s a breakdown of the content:\\n\\n* `Why did the pizza go to the doctor?`: This is the question part of the joke, setting up the unexpected punchline.\\n* `\\\\n\\\\nBecause it was feeling a little crusty.`: This is the answer part of the joke, where the pun is revealed. The word \"crusty\" has a double meaning here - it can refer to the crust of a pizza, but it can also imply that someone or something is a bit \"off\" or feeling unwell, which is why the pizza went to the doctor.\\n\\n**Additional Context and Metadata**\\n\\nThe additional_kwargs dictionary is empty, which means there are no additional parameters or context provided for this content.\\n\\nThe response_metadata dictionary provides information about the generation of this content:\\n\\n* `token_usage`: This section provides details about the token usage during the generation of this content, including the number of completion tokens, prompt tokens, total tokens, completion time, prompt time, queue time, and total time. The completion time is approximately 26 milliseconds, and the prompt time is approximately 2 milliseconds.\\n* `model_name`: The name of the model used to generate this content is `llama-3.1-8b-instant`.\\n* `system_fingerprint`: A unique identifier for the system that generated this content is `fp_7b3cfae3af`.\\n* `service_tier`: The service tier used to generate this content is `on_demand`.\\n* `finish_reason`: The reason why the content generation was stopped is `stop`.\\n* `logprobs`: This field is empty, indicating that no log probabilities were provided for this content.\\n* `model_provider`: The provider of the model used to generate this content is `groq`.\\n\\nThe id field is a unique identifier for this content generation run, and the usage_metadata dictionary provides information about the input and output tokens used during the generation of this content.\\n\\n**Usage Metadata**\\n\\nThe usage_metadata dictionary provides information about the usage of this content:\\n\\n* `input_tokens`: The number of input tokens used during the generation of this content is 40.\\n* `output_tokens`: The number of output tokens generated during the generation of this content is 20.\\n* `total_tokens`: The total number of tokens used during the generation of this content is 60.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 254, 'total_tokens': 754, 'completion_time': 0.831993883, 'prompt_time': 0.013884733, 'queue_time': 0.050841216, 'total_time': 0.845878616}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--be695141-5f79-4556-abff-1be29e4e6e2a-0', usage_metadata={'input_tokens': 254, 'output_tokens': 500, 'total_tokens': 754})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-8df9-6c57-8002-845193cfbb83'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-05T10:23:56.100514+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-82ee-68cb-8001-a8b46d9bfe7b'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}), 'topic': 'pizza'}, next=('JokeExplaination',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-82ee-68cb-8001-a8b46d9bfe7b'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-11-05T10:23:54.942484+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}}, tasks=(PregelTask(id='139d611b-a745-7d76-833f-46024cf900e7', name='JokeExplaination', path=('__pregel_pull', 'JokeExplaination'), error=None, interrupts=(), state=None, result={'explaination': AIMessage(content='**Explanation of Content: A Pizza-Related Pun**\\n\\nThe provided content is a simple joke in the format of a question and answer. Here\\'s a breakdown of the content:\\n\\n* `Why did the pizza go to the doctor?`: This is the question part of the joke, setting up the unexpected punchline.\\n* `\\\\n\\\\nBecause it was feeling a little crusty.`: This is the answer part of the joke, where the pun is revealed. The word \"crusty\" has a double meaning here - it can refer to the crust of a pizza, but it can also imply that someone or something is a bit \"off\" or feeling unwell, which is why the pizza went to the doctor.\\n\\n**Additional Context and Metadata**\\n\\nThe additional_kwargs dictionary is empty, which means there are no additional parameters or context provided for this content.\\n\\nThe response_metadata dictionary provides information about the generation of this content:\\n\\n* `token_usage`: This section provides details about the token usage during the generation of this content, including the number of completion tokens, prompt tokens, total tokens, completion time, prompt time, queue time, and total time. The completion time is approximately 26 milliseconds, and the prompt time is approximately 2 milliseconds.\\n* `model_name`: The name of the model used to generate this content is `llama-3.1-8b-instant`.\\n* `system_fingerprint`: A unique identifier for the system that generated this content is `fp_7b3cfae3af`.\\n* `service_tier`: The service tier used to generate this content is `on_demand`.\\n* `finish_reason`: The reason why the content generation was stopped is `stop`.\\n* `logprobs`: This field is empty, indicating that no log probabilities were provided for this content.\\n* `model_provider`: The provider of the model used to generate this content is `groq`.\\n\\nThe id field is a unique identifier for this content generation run, and the usage_metadata dictionary provides information about the input and output tokens used during the generation of this content.\\n\\n**Usage Metadata**\\n\\nThe usage_metadata dictionary provides information about the usage of this content:\\n\\n* `input_tokens`: The number of input tokens used during the generation of this content is 40.\\n* `output_tokens`: The number of output tokens generated during the generation of this content is 20.\\n* `total_tokens`: The total number of tokens used during the generation of this content is 60.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 254, 'total_tokens': 754, 'completion_time': 0.831993883, 'prompt_time': 0.013884733, 'queue_time': 0.050841216, 'total_time': 0.845878616}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--be695141-5f79-4556-abff-1be29e4e6e2a-0', usage_metadata={'input_tokens': 254, 'output_tokens': 500, 'total_tokens': 754})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-11-05T10:23:54.486053+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e8e-6f3f-bfff-ee51da96ffe7'}}, tasks=(PregelTask(id='fe3c3f28-2d6e-0f29-bf44-f96ab066cc17', name='joke', path=('__pregel_pull', 'joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e8e-6f3f-bfff-ee51da96ffe7'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-11-05T10:23:54.483897+00:00', parent_config=None, tasks=(PregelTask(id='89f85748-4545-34d7-04bf-46b8306aebb8', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b3ad989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza'}, next=('joke',), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-11-05T10:23:54.486053+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ba318-7e8e-6f3f-bfff-ee51da96ffe7'}}, tasks=(PregelTask(id='fe3c3f28-2d6e-0f29-bf44-f96ab066cc17', name='joke', path=('__pregel_pull', 'joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60})}),), interrupts=())"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({'configurable':{'thread_id':'1','checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a36f834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}),\n",
       " 'topic': 'pizza',\n",
       " 'explaination': AIMessage(content='**Content Analysis: A Playful Pizza Joke**\\n\\nThe provided content is a play on words, presenting a pizza-themed joke. The joke is structured as a question and answer, where the question \"Why did the pizza go to the doctor?\" is followed by the punchline \"Because it was feeling a little crusty.\"\\n\\n**Understanding the Joke:**\\n\\nThe joke relies on a clever use of language, where the word \"crusty\" has a double meaning. In culinary terms, a crusty pizza is one with a crunchy, hardened crust. However, in human experience, being \"feeling a little crusty\" can also imply being irritable or feeling under the weather, similar to having a cold or flu.\\n\\n**Key Language Features:**\\n\\n1. **Wordplay:** The joke exploits the dual meaning of the word \"crusty,\" creating a pun that connects the pizza\\'s culinary characteristic with a human emotional state.\\n2. **Misdirection:** The initial question sets up a expectation that the answer will be a serious medical reason for the pizza\\'s visit to the doctor, only to subvert it with a lighthearted and playful punchline.\\n3. **Simplistic yet effective:** The joke\\'s simplicity makes it accessible and easy to understand, while the unexpected twist creates a sense of surprise and delight.\\n\\n**Contextual Considerations:**\\n\\n1. **Audience:** The joke is likely intended for a general audience, particularly those who appreciate wordplay and puns.\\n2. **Tone:** The joke\\'s tone is lighthearted and playful, making it suitable for casual conversations or social media platforms.\\n3. **Cultural relevance:** The joke may not be universally relatable or funny, as pizza and its associated cultural context may vary across different regions and communities.\\n\\n**Conclusion:**\\n\\nThe provided content is a well-crafted play on words that leverages the dual meaning of the word \"crusty\" to create a humorous and engaging joke. Its simplicity, clever use of language, and lighthearted tone make it an effective and entertaining example of a pizza-themed joke.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 429, 'prompt_tokens': 254, 'total_tokens': 683, 'completion_time': 0.811722195, 'prompt_time': 0.013900066, 'queue_time': 0.049151724, 'total_time': 0.825622261}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--dfa2a6b5-e6e9-49ef-aeea-d422d2621faa-0', usage_metadata={'input_tokens': 254, 'output_tokens': 429, 'total_tokens': 683})}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {'configurable':{'thread_id':'1','checkpoint_id': '1f0ba318-82ee-68cb-8001-a8b46d9bfe7b' }})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bbacb",
   "metadata": {},
   "source": [
    "## Updating the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abdb31c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ba359-2d88-67a0-8001-adf795b5c575'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({'configurable':{'thread_id':'1','checkpoint_id': '1f0ba318-7e94-637b-8000-14deb1b221e8',\"checkpoint_ns\": \"\"}}, {'topic':'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60513efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 40, 'total_tokens': 60, 'completion_time': 0.026720254, 'prompt_time': 0.001763828, 'queue_time': 0.048630892, 'total_time': 0.028484082}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7f16268f-97c4-4060-9097-b29612c50717-0', usage_metadata={'input_tokens': 40, 'output_tokens': 20, 'total_tokens': 60}),\n",
       " 'topic': 'samosa',\n",
       " 'explaination': AIMessage(content='**Content Analysis: \"Why did the pizza go to the doctor?\"**\\n\\nThe given content is a joke with a punchline. The question \"Why did the pizza go to the doctor?\" is a classic setup for a joke, and the response \"Because it was feeling a little crusty\" is a play on words.\\n\\nHere\\'s a breakdown of the joke\\'s components:\\n\\n1. **Setup**: The question \"Why did the pizza go to the doctor?\" creates a mental expectation for a typical reason why someone might visit a doctor, such as feeling unwell.\\n2. **Punchline**: The response \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling under the weather,\" which is a common idiomatic expression for being unwell. However, in this case, \"crusty\" refers to the crust of a pizza, creating a pun.\\n\\nThis type of joke relies on the listener\\'s understanding of the wordplay and the clever use of language to create a humorous effect.\\n\\n**Response Metadata**\\n\\nThe provided response metadata includes information about the model\\'s performance and usage:\\n\\n* **Model Name**: The model used is LLaMA-3.1-8b-instant, which is a large language model.\\n* **Token Usage**: The model used 20 completion tokens, 40 prompt tokens, and a total of 60 tokens. The completion time was approximately 26 milliseconds.\\n* **Finish Reason**: The model stopped generating output due to a user-initiated stop.\\n* **Service Tier**: The service tier used is on-demand, which means the model was run on-demand and not as part of a batch process.\\n\\nOverall, the response metadata provides useful information about the model\\'s performance and usage, which can be helpful for understanding and optimizing the model\\'s behavior.\\n\\n**Usage Metadata**\\n\\nThe provided usage metadata includes information about the input and output:\\n\\n* **Input Tokens**: The input prompt contained 40 tokens.\\n* **Output Tokens**: The model generated 20 tokens as output.\\n* **Total Tokens**: The total number of tokens used was 60.\\n\\nThis metadata provides a clear picture of the input and output of the model, which can be helpful for understanding the model\\'s performance and optimizing its behavior.\\n\\n**Additional Keywords**\\n\\nThere are no additional keywords provided in the response metadata.\\n\\n**System Fingerprint**\\n\\nThe system fingerprint is fp_7b3cfae3af, which is a unique identifier for the system.\\n\\n**Model Provider**\\n\\nThe model provider is Groq, which is a company that provides large language models.\\n\\n**Logprobs**\\n\\nThe logprobs value is None, which means that the model did not generate any log probabilities.\\n\\n**Finish Reason**\\n\\nThe finish reason is stop, which means that the model stopped generating output due to a user-initiated stop.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 570, 'prompt_tokens': 254, 'total_tokens': 824, 'completion_time': 0.808035689, 'prompt_time': 0.014026899, 'queue_time': 0.054143491, 'total_time': 0.822062588}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--8a3a62a1-edd1-4f31-9145-fd20f127f159-0', usage_metadata={'input_tokens': 254, 'output_tokens': 570, 'total_tokens': 824})}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, {'configurable':{'thread_id':'1','checkpoint_id': '1f0ba359-2d88-67a0-8001-adf795b5c575' }})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
